{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data Cleaning.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"_mGNUzbTTUkX","colab_type":"code","outputId":"cefd9307-a0cf-4c35-a05f-17028ee8365e","colab":{}},"cell_type":"code","source":["import os\n","import re\n","import csv\n","import sys\n","import numpy as np\n","import pandas as pd\n","import spacy\n","import operator\n","import nltk\n","import multiprocessing as mp\n","from translate import Translator\n","from nltk.corpus import stopwords\n","from nltk.stem import SnowballStemmer\n","from string import punctuation\n","from collections import defaultdict\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"tsfIa0uQTUkh","colab_type":"code","colab":{}},"cell_type":"code","source":["#nltk.download('stopwords')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"In1dtmvgTUko","colab_type":"code","colab":{}},"cell_type":"code","source":["train = pd.read_csv(\"train.csv\")\n","test = pd.read_csv(\"test.csv\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MQ6ZJ8-pTUkt","colab_type":"code","outputId":"15f485b2-2087-4f48-c643-978bf74e5fee","colab":{}},"cell_type":"code","source":["nrow_train=train.shape[0]\n","nrow_test=test.shape[0]\n","print(\"train:\",nrow_train, \"rows\")\n","print(\"test :\",nrow_test, \"rows\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train: 159571 rows\n","test : 153164 rows\n"],"name":"stdout"}]},{"metadata":{"id":"o5ysh4OUTUky","colab_type":"code","colab":{}},"cell_type":"code","source":["# Check null values is train and test\n","#train.isnull().any()\n","#test.isnull().any()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4LKUV7JyTUk6","colab_type":"code","outputId":"79a0353c-f179-4927-e113-d8be11c2519b","colab":{}},"cell_type":"code","source":["train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000997932d777bf</td>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000103f0d9cfb60f</td>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000113f07ec002fd</td>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001d958c54c6e35</td>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 id                                       comment_text  toxic  \\\n","0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n","1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n","2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n","3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n","4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n","\n","   severe_toxic  obscene  threat  insult  identity_hate  \n","0             0        0       0       0              0  \n","1             0        0       0       0              0  \n","2             0        0       0       0              0  \n","3             0        0       0       0              0  \n","4             0        0       0       0              0  "]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"eDL07h7PTUlB","colab_type":"text"},"cell_type":"markdown","source":["### Data Cleaning"]},{"metadata":{"id":"3Ak3EdvETUlD","colab_type":"text"},"cell_type":"markdown","source":["#### 1. Lowercase 2.Fix typo 3.Remove numbers, odd characters, stopwords, image, templates 4.Replace numbers with language"]},{"metadata":{"id":"SeQ_VQG0TUlF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load the cleaned words\n","cl_path = 'cleanwords.txt'\n","clean_word_dict = {}\n","with open(cl_path, 'r', encoding='utf-8') as cl:\n","    for line in cl:\n","        line = line.strip('\\n')\n","        typo, correct = line.split(',')\n","        clean_word_dict[typo] = correct"],"execution_count":0,"outputs":[]},{"metadata":{"id":"arJdfx2DTUlJ","colab_type":"code","colab":{}},"cell_type":"code","source":["stop_words = stopwords.words('english')\n","def clean_text(text):\n","    text = text.lower()\n","    # Removed url links and ip addresses\n","    text = re.sub(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", \"\", text)\n","    text = re.sub(r\"(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}\", \"\", text)\n","    \n","    # Remove stopwords\n","    text = \" \".join([w for w in text.split() if w not in stop_words])\n","    \n","    # Remove all punctuations\n","    #text = text.str.replace('[^\\w\\s]','')\n","    \n","    # Clean typo(NOT misspelling)\n","    for typo, correct in clean_word_dict.items():\n","        text = re.sub(typo, \" \" + correct + \" \", text)\n","\n","    # Clean other words\n","    text = re.sub(r\"what's\", \"what is \", text)\n","    text = re.sub(r\"\\'s\", \" \", text)\n","    text = re.sub(r\"\\n\", \" \", text)\n","    text = re.sub(r\"&\", \"and\", text)\n","    text = re.sub(r\"@\", \"at\", text)\n","    # Replaced words that have a special symbol in between them \n","    text = re.sub(r\"\\'ve\", \" have \", text)\n","    text = re.sub(r\"can't\", \"cannot \", text)\n","    text = re.sub(r\"n't\", \" not \", text)\n","    text = re.sub(r\"i'm\", \"i am \", text)\n","    text = re.sub(r\"\\'re\", \" are \", text)\n","    text = re.sub(r\"\\'d\", \" would \", text)\n","    text = re.sub(r\"\\'ll\", \" will \", text)\n","    text = re.sub(r\",\", \" \", text)\n","    text = re.sub(r\"\\.\", \" \", text)\n","    text = re.sub(r\"!\", \" ! \", text)\n","    text = re.sub(r\"\\/\", \" \", text)\n","    text = re.sub(r\"\\?\", \" ? \", text)\n","    text = re.sub(r\"\\!\", \" ! \", text)\n","    text = re.sub(r\"\\\"\", \" \", text)\n","    text = re.sub(r\"\\^\", \" ^ \", text)\n","    text = re.sub(r\"\\+\", \" + \", text)\n","    text = re.sub(r\"\\-\", \" - \", text)\n","    text = re.sub(r\"\\=\", \" = \", text)\n","    text = re.sub(r\"'\", \" \", text)\n","    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n","    text = re.sub(r\":\", \" : \", text)\n","    text = re.sub(r\" e g \", \" eg \", text)\n","    text = re.sub(r\" b g \", \" bg \", text)\n","    text = re.sub(r\" u s \", \" american \", text)\n","    text = re.sub(r\"\\0s\", \"0\", text)\n","    text = re.sub(r\" 9 11 \", \"911\", text)\n","    text = re.sub(r\"e - mail\", \"email\", text)\n","    text = re.sub(r\"j k\", \"jk\", text)\n","    text = re.sub(r\"\\s{2,}\", \" \", text)\n","    \n","    # Replace numbers with language\n","    text = text.replace('0', ' zero ')\n","    text = text.replace('1', ' one ')\n","    text = text.replace('2', ' two ')\n","    text = text.replace('3', ' three ')\n","    text = text.replace('4', ' four ')\n","    text = text.replace('5', ' five ')\n","    text = text.replace('6', ' six ')\n","    text = text.replace('7', ' seven ')\n","    text = text.replace('8', ' eight ')\n","    text = text.replace('9', ' nine ')\n","    \n","    # Drop the image\n","    text = re.sub(r\"image:[a-zA-Z0-9]*\\.jpg\", \" \", text)\n","    text = re.sub(r\"image:[a-zA-Z0-9]*\\.png\", \" \", text)\n","    text = re.sub(r\"image:[a-zA-Z0-9]*\\.gif\", \" \", text)\n","    text = re.sub(r\"image:[a-zA-Z0-9]*\\.bmp\", \" \", text)\n","\n","    # Drop CSS\n","    text = re.sub(r\"#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})\", \" \",text)\n","    text = re.sub(r\"\\{\\|[^\\}]*\\|\\}\", \" \", text)\n","        \n","    # Clean templates\n","    text = re.sub(r\"\\[?\\[user:.*\\]\", \" \", text)\n","    text = re.sub(r\"\\[?\\[user:.*\\|\", \" \", text)        \n","    text = re.sub(r\"\\[?\\[wikipedia:.*\\]\", \" \", text)\n","    text = re.sub(r\"\\[?\\[wikipedia:.*\\|\", \" \", text)\n","    text = re.sub(r\"\\[?\\[special:.*\\]\", \" \", text)\n","    text = re.sub(r\"\\[?\\[special:.*\\|\", \" \", text)\n","    text = re.sub(r\"\\[?\\[category:.*\\]\", \" \", text)\n","    text = re.sub(r\"\\[?\\[category:.*\\|\", \" \", text)\n","    \n","    return (text)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pepy5EAoTUlQ","colab_type":"code","colab":{}},"cell_type":"code","source":["list_sentences_train = train[\"comment_text\"].fillna(\"no comment\").values\n","list_sentences_test = test[\"comment_text\"].fillna(\"no comment\").values\n","\n","train['comment_text'] = train['comment_text'].apply(clean_text)\n","test['comment_text'] = test['comment_text'].apply(clean_text)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v0enFwY6TUlW","colab_type":"code","outputId":"125198a9-6fa7-4bb4-d80e-f6d45f7f8200","colab":{}},"cell_type":"code","source":["train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000997932d777bf</td>\n","      <td>explanation edits made username hardcore metal...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000103f0d9cfb60f</td>\n","      <td>d aww ! matches background colour i am seeming...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000113f07ec002fd</td>\n","      <td>hey man i am really trying edit war guy consta...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>cannot make real suggestions improvement - wo...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001d958c54c6e35</td>\n","      <td>you sir hero chance remember page that on ?</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 id                                       comment_text  toxic  \\\n","0  0000997932d777bf  explanation edits made username hardcore metal...      0   \n","1  000103f0d9cfb60f  d aww ! matches background colour i am seeming...      0   \n","2  000113f07ec002fd  hey man i am really trying edit war guy consta...      0   \n","3  0001b41b1c6bb37e   cannot make real suggestions improvement - wo...      0   \n","4  0001d958c54c6e35       you sir hero chance remember page that on ?       0   \n","\n","   severe_toxic  obscene  threat  insult  identity_hate  \n","0             0        0       0       0              0  \n","1             0        0       0       0              0  \n","2             0        0       0       0              0  \n","3             0        0       0       0              0  \n","4             0        0       0       0              0  "]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"oDSSpOoqTUld","colab_type":"text"},"cell_type":"markdown","source":["### Translation"]},{"metadata":{"id":"ClvRWzpQTUle","colab_type":"code","colab":{}},"cell_type":"code","source":["translator = Translator(to_lang = 'en')\n","train['comment_text'] = train['comment_text'].apply(translator.translate)\n","test['comment_text'] = test['comment_text'].apply(translator.translate)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_fGs_mOSTUlh","colab_type":"text"},"cell_type":"markdown","source":["### Lemmatization"]},{"metadata":{"id":"nh7ziL3ITUlk","colab_type":"code","colab":{}},"cell_type":"code","source":["def lemmatize(text):\n","    text = nlp(text)\n","    lemmatized = list()\n","    for word in text:\n","        lemma = word.lemma_.strip()\n","        lemmatized.append(lemma)\n","    return \" \".join(lemmatized)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C9rwvbzBTUlp","colab_type":"code","colab":{}},"cell_type":"code","source":["nlp = spacy.load('en')\n","train['comment_text'] = train['comment_text'].apply(lemmatize)\n","test['comment_text'] = test['comment_text'].apply(lemmatize)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-LEdMLDwTUlu","colab_type":"text"},"cell_type":"markdown","source":["### Stemming - might be too aggressive to use"]},{"metadata":{"id":"Y2SVR6ydTUlw","colab_type":"code","colab":{}},"cell_type":"code","source":["#def stemming(text):\n","#    text = text.split()\n","#    stemmer = SnowballStemmer('english')\n","#    stemmed_words = [stemmer.stem(word) for word in text]\n","#    text = \" \".join(stemmed_words)\n","#    return text"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rtuYsHhSTUlz","colab_type":"code","colab":{}},"cell_type":"code","source":["#train['comment_text'] = train['comment_text'].apply(stemming)\n","#test['comment_text'] = test['comment_text'].apply(stemming)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KWPs_OC8TUl7","colab_type":"text"},"cell_type":"markdown","source":["### Pos taggings\n","Generate the part of speech (POS) tagging for every comment by TextBlob and concatenate the word embedding and POS embedding as a single one. \n","Since TextBlob drops some tokens and punctuations when generating the POS sequences, this may give our models another view."]},{"metadata":{"id":"TJ2g9G7wTUl9","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_pos(x):\n","    tokens = nltk.tokenize.word_tokenize(x)\n","    tags = nltk.pos_tag(tokens)\n","    return tags"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ThmG5eAwTUmD","colab_type":"code","colab":{}},"cell_type":"code","source":["pool = mp.Pool(4)\n","train_pos = pool.map(get_pos, train['comment_text'])\n","test_pos = pool.map(get_pos, test['comment_text'])\n","pool.terminate()  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"tzR9XmhqTUmH","colab_type":"code","colab":{}},"cell_type":"code","source":["# save results\n","train_pos = pd.DataFrame({'pos': train_pos})\n","train_pos.to_csv('train_pos.csv', index=False)\n","test_pos = pd.DataFrame({'pos': test_pos})\n","test_pos.to_csv('test_pos.csv', index=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NQuAN_wfTUmK","colab_type":"text"},"cell_type":"markdown","source":["### Feature engineering"]},{"metadata":{"id":"Cn9mLVCuTUmL","colab_type":"code","colab":{}},"cell_type":"code","source":["def add_features(df):\n","    df['comment_text'] = df['comment_text'].apply(lambda x:str(x))\n","    df['total_length'] = df['comment_text'].apply(len)+1\n","    df['capitals'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n","    df['caps_vs_length'] = df.apply(lambda row: float(row['capitals'])/float(row['total_length']),axis=1)\n","    df['num_words'] = df.comment_text.str.count('\\S+')\n","    df['num_unique_words'] = df['comment_text'].apply(lambda comment: len(set(w for w in comment.split())))\n","    df['words_vs_unique'] = df['num_unique_words'] / df['num_words']  \n","    df[['caps_vs_length', 'words_vs_unique']] = df[['caps_vs_length', 'words_vs_unique']].fillna(0)\n","    return df"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ut1hMY6tTUmT","colab_type":"code","colab":{}},"cell_type":"code","source":["train = add_features(train)\n","test = add_features(test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3KC5Nd_NTUmY","colab_type":"code","colab":{}},"cell_type":"code","source":["train.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_wnpdDqzTUmb","colab_type":"code","colab":{}},"cell_type":"code","source":["train.to_csv('clean_train.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L3Uocs6bTUmd","colab_type":"code","colab":{}},"cell_type":"code","source":["test.to_csv('clean_test.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b23jeXUbTUmh","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}